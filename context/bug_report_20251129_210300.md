Bug Fixes & Extended Report Implementation Plan
Status: Ready to Implement Version: v2.0 Prerequisites: âœ… Graph export & visualization features implemented (v1.0 complete)
Overview
Fix critical bugs in the interview system and add extended reporting capability:
Issues to Fix:
âŒ Export buttons not working (Gradio 6.x compatibility)
âŒ Data tables showing "[object Object]" (format incompatibility)
âš ï¸ Graph interpretation unclear (disconnected nodes, question loops)
New Feature:
ğŸ†• Extended Markdown report with turn-by-turn breakdown and richness scoring details
Implementation Priority:
Phase 1: Fix export buttons + data tables (CRITICAL - quick fixes)
Phase 2: Investigate graph extraction issues (MEDIUM - requires analysis)
Phase 3: Add extended report feature (NEW FEATURE - full implementation)
Issue Analysis Summary
Issue 1: Export Buttons Not Working
Root Cause: Gradio 6.x changed security model - visible=False File components block downloads Impact: Users cannot download GraphML, JSON, or transcript files Fix Complexity: Low (5 min)
Issue 2: Data Tables Showing "[object Object]"
Root Cause: Gradio 6.x Dataframe expects list[list], not list[dict] Impact: Node and edge tables are unreadable Fix Complexity: Low (10 min)
Issue 3: Graph Extraction Issues
Observed Problems:
Many disconnected nodes (no edges between concepts)
Question generation loops (asked about monthly delivery 3+ times despite user saying weekly)
User's interview transcript shows rich discussion but graph doesn't capture relationships
Potential Causes:
LLM not extracting edges from responses
Validation filtering out valid edges
Question generation not using graph context effectively
Fix Complexity: Medium-High (requires investigation + fixes)
Issue 4: Extended Report Feature
Requirements:
Markdown format (human-readable, version-controllable)
Turn-by-turn Q&A with timestamps
LLM metadata per turn (model, tokens, latency)
Extracted nodes/edges per turn with quotes
Validation errors/warnings
Richness score breakdown showing: which nodes were extracted, their weights, and how they sum to the score increase
No charts - simple text-based view
Current State:
80% of infrastructure exists (GraphDelta.extraction_metadata, LLMResponse, conversation_history)
TurnLog model exists but is completely unused
Data flows through memory but isn't persisted
Fix Complexity: High (2-3 hours for full implementation)
Architecture Changes
Files to Modify:
src/ui/
â”œâ”€â”€ gradio_app.py (MODIFY)
â”‚   â”œâ”€â”€ Fix: get_node_table() â†’ return list[list] instead of list[dict]
â”‚   â”œâ”€â”€ Fix: get_edge_table() â†’ return list[list] instead of list[dict]
â”‚   â”œâ”€â”€ Fix: File components visible=True
â”‚   â”œâ”€â”€ Fix: Make export handlers async
â”‚   â”œâ”€â”€ New: export_extended_report() â†’ str (Markdown)
â”‚   â””â”€â”€ New: Extended report export button + handler

src/interview/
â”œâ”€â”€ interview_manager.py (MODIFY)
â”‚   â”œâ”€â”€ New: turn_logs: list[TurnLog] = []
â”‚   â”œâ”€â”€ Modify: Store TurnLog after each response
â”‚   â””â”€â”€ New: get_turn_logs() â†’ list[TurnLog]

src/reporting/
â””â”€â”€ report_generator.py (NEW)
    â””â”€â”€ generate_markdown_report(turn_logs, session_info) â†’ str

src/core/
â””â”€â”€ data_models.py (VERIFY)
    â””â”€â”€ TurnLog model already exists - just need to use it
Data Flow
User clicks "Export Graph" button
    â†“
InterviewUI.export_graph()
    â†“
InterviewSession.export_graphml/json/transcript()
    â†“
gr.File download (GraphML/JSON/TXT)

User views "Graph Visualization" tab
    â†“
InterviewUI updates gr.Plot component
    â†“
InterviewSession.visualize_graph()
    â†“
graph_visualizer.create_plotly_graph()
    â†“
Plotly interactive figure (hover, zoom, pan)
PHASE 1: Critical Bug Fixes (Priority: HIGHEST)
1.1 Fix Export Buttons (Gradio 6.x Compatibility)
Problem: visible=False on File components prevents downloads in Gradio 6.x File: src/ui/gradio_app.py Changes:
Change File component visibility (lines 364-389):
# Before:
graphml_file = gr.File(
    label="GraphML File (for Gephi, yEd, Cytoscape)",
    visible=False  # âŒ BLOCKS DOWNLOADS
)

# After:
graphml_file = gr.File(
    label="GraphML File (for Gephi, yEd, Cytoscape)",
    visible=True  # âœ… ENABLES DOWNLOADS
)
Apply same fix to json_file and transcript_file components.
Make export handlers async (lines 245-305):
# Before:
def export_graphml_file(self):
    """Export GraphML file for download."""

# After:
async def export_graphml_file(self):
    """Export GraphML file for download."""
Apply to all three export handlers: export_graphml_file(), export_json_file(), export_transcript_file()
Add error handling and logging:
async def export_graphml_file(self):
    """Export GraphML file for download."""
    try:
        if not self.current_session or not self.current_session.manager:
            logger.warning("Export attempted with no active session")
            return None

        logger.info(f"Exporting GraphML for session {self.current_session.session_id}")
        graphml_bytes = self.current_session.export_graphml()

        # ... rest of implementation ...

        logger.info(f"GraphML export successful: {temp_file.name}")
        return temp_file.name

    except Exception as e:
        logger.error(f"GraphML export failed: {e}")
        return None
Testing: After fix, clicking export buttons should trigger browser download
1.2 Fix Data Tables (Format Conversion)
Problem: Gradio 6.x Dataframe expects list[list], but code returns list[dict] File: src/ui/gradio_app.py Changes:
Fix get_node_table() (lines 234-253):
# Before:
def get_node_table(self) -> list[dict]:
    """Get node data as table rows."""
    if not self.manager:
        return []

    rows = []
    for node_id in self.manager.graph.graph.nodes():
        node_data = self.manager.graph.graph.nodes[node_id]["data"]
        rows.append({
            "ID": node_data.id,
            "Type": node_data.type,
            "Label": node_data.label,
            "Quotes": "; ".join(node_data.source_quotes[:2]),
            "Visit Count": node_data.visit_count,
            "Turn": node_data.creation_turn,
        })
    return rows

# After:
def get_node_table(self) -> list[list]:
    """Get node data as table rows (list[list] format for Gradio 6.x)."""
    if not self.manager:
        return []

    rows = []
    for node_id in self.manager.graph.graph.nodes():
        node_data = self.manager.graph.graph.nodes[node_id]["data"]
        # Return list in same order as headers: ID, Type, Label, Quotes, Visit Count, Turn
        rows.append([
            node_data.id,
            node_data.type,
            node_data.label,
            "; ".join(node_data.source_quotes[:2]),
            node_data.visit_count,
            node_data.creation_turn,
        ])
    return rows
Fix get_edge_table() (lines 255-277):
# Before:
def get_edge_table(self) -> list[dict]:
    """Get edge data as table rows."""
    if not self.manager:
        return []

    rows = []
    for _, _, edge_data in self.manager.graph.graph.edges(data=True):
        edge = edge_data["data"]
        quote = (
            edge.source_quote[:50] + "..." if len(edge.source_quote) > 50 else edge.source_quote
        )
        rows.append({
            "ID": edge.id,
            "Type": edge.type,
            "Source": edge.source,
            "Target": edge.target,
            "Quote": quote,
            "Turn": edge.creation_turn,
        })
    return rows

# After:
def get_edge_table(self) -> list[list]:
    """Get edge data as table rows (list[list] format for Gradio 6.x)."""
    if not self.manager:
        return []

    rows = []
    for _, _, edge_data in self.manager.graph.graph.edges(data=True):
        edge = edge_data["data"]
        quote = (
            edge.source_quote[:50] + "..." if len(edge.source_quote) > 50 else edge.source_quote
        )
        # Return list in same order as headers: ID, Type, Source, Target, Quote, Turn
        rows.append([
            edge.id,
            edge.type,
            edge.source,
            edge.target,
            quote,
            edge.creation_turn,
        ])
    return rows
Critical: Order of elements in the list MUST match the order of headers in the Dataframe component Testing: After fix, tables should display actual data values instead of "[object Object]"
PHASE 2: Graph Extraction Investigation (Priority: MEDIUM)
2.1 Analyze User's Interview Transcript
User's Interview Summary:
Topic: Coffee subscription service
Key themes: local coffee, freshness, weekly vs monthly delivery, cost (~Â£10/week), coffee going stale
Issue: Interviewer looped on monthly delivery question despite user preferring weekly (asked 3+ times)
Expected graph:
Nodes: local, freshness, weekly_delivery, cost_sensitivity, stale_coffee, quality
Edges: localâ†’freshness, monthly_deliveryâ†’stale_coffeeâ†’bad_taste, freshnessâ†’quality
Observed graph: Many disconnected nodes (from screenshots)
2.2 Investigation Tasks
Check edge extraction from user's interview:
Export JSON from the user's session
Count edges vs nodes
Identify which relationships were missed
Review validation logs:
Check if edges were extracted but rejected by Validator
Look for validation errors in extraction_metadata
Test question generation:
Why did interviewer ask about monthly delivery repeatedly?
Check if question generator is using graph context (expansion opportunities)
Review question selection logic in QuestionGenerator
Add graph interpretation guide:
Document what colors mean (node types)
Explain what node size indicates (richness weight + visit count)
Explain what edges represent (causal relationships)
Add this to UI as an info accordion in Graph Visualization tab
2.3 Potential Fixes
If edges aren't being extracted:
Review prompt templates in prompts/extraction_prompts.yaml
Check if LLM is being asked to extract edges in response extraction
Test with more explicit edge extraction prompts
If edges are being filtered out:
Review Validator edge validation rules
Check if edge types are valid in schema
Relax validation if too strict
If question generation is looping:
Fix QuestionGenerator to check conversation history
Add diversity penalty for repeated topics
Use graph expansion opportunities more effectively
PHASE 3: Extended Report Feature (Priority: NEW FEATURE)
3.1 Overview
Create detailed Markdown report showing turn-by-turn interview breakdown with richness scoring details.
3.2 Data Storage Infrastructure
File: src/interview/interview_manager.py Add turn logging:
from src.core.data_models import TurnLog

class InterviewManager:
    def __init__(...):
        # ... existing init ...
        self.turn_logs: list[TurnLog] = []  # NEW: Store turn history

    async def process_response(self, user_response: str) -> str:
        """Process response and generate next question."""
        # ... existing extraction logic ...

        # NEW: Create turn log
        turn_log = TurnLog(
            turn_number=self.turn_number,
            user_response=user_response,
            ai_question=next_question,
            extraction_metadata=delta.extraction_metadata,
            nodes_added=[node.dict() for node in delta.nodes_added],
            edges_added=[edge.dict() for edge in delta.edges_added],
            richness_delta=delta.richness_score,
            cumulative_richness=self.graph.calculate_richness(),
            timestamp=datetime.now().isoformat(),
        )

        self.turn_logs.append(turn_log)

        # ... rest of method ...

    def get_turn_logs(self) -> list[TurnLog]:
        """Get all turn logs for extended reporting."""
        return self.turn_logs
Verify TurnLog model in src/core/data_models.py:
class TurnLog(BaseModel):
    """Log entry for a single interview turn."""
    turn_number: int
    user_response: str
    ai_question: str
    extraction_metadata: dict
    nodes_added: list[dict]  # Serialized Node objects
    edges_added: list[dict]  # Serialized Edge objects
    richness_delta: float
    cumulative_richness: float
    timestamp: str
If model doesn't exist, create it. If it exists but missing fields, update it.
3.3 Report Generator
New File: src/reporting/report_generator.py
"""
Extended report generator for interview sessions.

Generates detailed Markdown reports with turn-by-turn breakdown,
richness scoring details, and LLM metadata.
"""

import logging
from datetime import datetime
from typing import List

from src.core.data_models import TurnLog

logger = logging.getLogger(__name__)


class ReportGenerator:
    """Generate extended Markdown reports for interview sessions."""

    @staticmethod
    def generate_markdown_report(
        session_id: str,
        concept_description: str,
        turn_logs: List[TurnLog],
        final_graph_stats: dict,
    ) -> str:
        """
        Generate comprehensive Markdown report.

        Args:
            session_id: Session identifier
            concept_description: Concept being interviewed about
            turn_logs: List of turn logs from interview
            final_graph_stats: Final graph statistics

        Returns:
            Markdown formatted report string
        """
        lines = []

        # Header
        lines.extend([
            "# Extended Interview Report",
            "",
            f"**Session ID:** `{session_id}`",
            f"**Concept:** {concept_description}",
            f"**Date:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            f"**Total Turns:** {len(turn_logs)}",
            "",
            "---",
            "",
        ])

        # Summary Statistics
        lines.extend([
            "## Summary Statistics",
            "",
            f"- **Total Nodes Extracted:** {final_graph_stats.get('nodes', 0)}",
            f"- **Total Edges Extracted:** {final_graph_stats.get('edges', 0)}",
            f"- **Final Richness Score:** {final_graph_stats.get('richness', 0.0):.2f}",
            f"- **Schema Coverage:** {final_graph_stats.get('coverage', '0%')}",
            "",
            "---",
            "",
        ])

        # Turn-by-turn breakdown
        lines.extend([
            "## Turn-by-Turn Analysis",
            "",
        ])

        for turn_log in turn_logs:
            lines.extend(ReportGenerator._format_turn(turn_log))
            lines.append("")

        # Metadata summary
        lines.extend([
            "---",
            "",
            "## LLM Usage Summary",
            "",
        ])

        total_tokens = sum(
            log.extraction_metadata.get("tokens_used", 0) for log in turn_logs
        )
        avg_latency = (
            sum(log.extraction_metadata.get("latency_ms", 0) for log in turn_logs)
            / len(turn_logs)
            if turn_logs
            else 0
        )

        lines.extend([
            f"- **Total Tokens Used:** {total_tokens:,}",
            f"- **Average Latency:** {avg_latency:.0f}ms",
            f"- **Extraction Model:** {turn_logs[0].extraction_metadata.get('model_used', 'Unknown') if turn_logs else 'N/A'}",
            "",
        ])

        return "\n".join(lines)

    @staticmethod
    def _format_turn(turn_log: TurnLog) -> List[str]:
        """Format a single turn log as Markdown."""
        lines = []

        # Turn header
        lines.extend([
            f"### Turn {turn_log.turn_number}",
            "",
            f"**Timestamp:** {turn_log.timestamp}",
            "",
        ])

        # Q&A
        lines.extend([
            "**Participant Response:**",
            f"> {turn_log.user_response}",
            "",
            "**Interviewer Question:**",
            f"> {turn_log.ai_question}",
            "",
        ])

        # Extraction details
        lines.extend([
            "#### Extraction Results",
            "",
        ])

        # Nodes extracted
        if turn_log.nodes_added:
            lines.extend([
                "**Nodes Added:**",
                "",
            ])
            for node in turn_log.nodes_added:
                lines.append(
                    f"- **{node['label']}** ({node['type']})"
                )
                if node.get('source_quotes'):
                    lines.append(f"  - Quote: \"{node['source_quotes'][0]}\"")
            lines.append("")
        else:
            lines.extend(["*No nodes extracted this turn*", ""])

        # Edges extracted
        if turn_log.edges_added:
            lines.extend([
                "**Edges Added:**",
                "",
            ])
            for edge in turn_log.edges_added:
                lines.append(
                    f"- {edge['source']} â†’ {edge['target']} ({edge['type']})"
                )
                if edge.get('source_quote'):
                    lines.append(f"  - Quote: \"{edge['source_quote'][:50]}...\"")
            lines.append("")
        else:
            lines.extend(["*No edges extracted this turn*", ""])

        # Richness score breakdown
        lines.extend([
            "#### Richness Score Breakdown",
            "",
            f"**Score Increase This Turn:** +{turn_log.richness_delta:.2f}",
            "",
        ])

        if turn_log.nodes_added:
            lines.append("**Contribution by Node:**")
            lines.append("")
            # Note: We need node richness weights - this requires passing schema to report generator
            # For now, show which nodes contributed
            for node in turn_log.nodes_added:
                lines.append(f"- {node['label']} ({node['type']}): +weight")
            lines.append("")

        lines.extend([
            f"**Cumulative Richness:** {turn_log.cumulative_richness:.2f}",
            "",
        ])

        # LLM metadata
        metadata = turn_log.extraction_metadata
        lines.extend([
            "#### LLM Metadata",
            "",
            f"- Model: `{metadata.get('model_used', 'Unknown')}`",
            f"- Tokens: {metadata.get('tokens_used', 0)}",
            f"- Latency: {metadata.get('latency_ms', 0)}ms",
        ])

        # Validation issues
        if metadata.get('validation_errors'):
            lines.extend([
                "",
                "**Validation Errors:**",
                "",
            ])
            for error in metadata['validation_errors']:
                lines.append(f"- âš ï¸ {error}")

        if metadata.get('validation_warnings'):
            lines.extend([
                "",
                "**Validation Warnings:**",
                "",
            ])
            for warning in metadata['validation_warnings']:
                lines.append(f"- âš¡ {warning}")

        lines.append("")
        lines.append("---")

        return lines
Note: To show actual richness weights in the breakdown, we need to pass the SchemaManager to the report generator so it can look up weights by node type.
3.4 UI Integration
File: src/ui/gradio_app.py Add export method to InterviewSession:
def export_extended_report(self) -> str:
    """Export extended Markdown report."""
    if not self.manager:
        return "# No Interview Data\n\nNo interview has been conducted yet."

    from src.reporting.report_generator import ReportGenerator

    report = ReportGenerator.generate_markdown_report(
        session_id=self.session_id,
        concept_description=self.concept_description,
        turn_logs=self.manager.get_turn_logs(),
        final_graph_stats=self.get_stats(),
    )

    return report
Add export handler to InterviewUI:
async def export_extended_report_file(self):
    """Export extended report file for download."""
    try:
        if not self.current_session or not self.current_session.manager:
            logger.warning("Extended report export attempted with no active session")
            return None

        logger.info(f"Exporting extended report for session {self.current_session.session_id}")

        import tempfile

        report_markdown = self.current_session.export_extended_report()

        temp_file = tempfile.NamedTemporaryFile(
            mode="w",
            suffix=".md",
            delete=False,
            prefix=f"extended_report_{self.current_session.session_id}_",
        )
        temp_file.write(report_markdown)
        temp_file.close()

        logger.info(f"Extended report export successful: {temp_file.name}")
        return temp_file.name

    except Exception as e:
        logger.error(f"Extended report export failed: {e}")
        return None
Add UI button in Export tab:
# In build_interface(), Export tab section:

with gr.Column():
    gr.Markdown("**Conversation**")

    export_transcript_btn = gr.Button(
        "ğŸ“¥ Download Transcript",
        variant="secondary",
        size="lg",
    )
    transcript_file = gr.File(
        label="Transcript File (text)",
        visible=True,  # FIXED
    )

    # NEW: Extended report button
    export_extended_report_btn = gr.Button(
        "ğŸ“¥ Download Extended Report (Markdown)",
        variant="primary",  # Primary = recommended option
        size="lg",
    )
    extended_report_file = gr.File(
        label="Extended Report (Markdown with turn-by-turn breakdown)",
        visible=True,
    )

# Wire up event handler:
export_extended_report_btn.click(
    fn=self.export_extended_report_file,
    outputs=[extended_report_file],
)
PHASE 4: Documentation & Testing
4.1 Graph Interpretation Guide
Add to Graph Visualization tab:
# In build_interface(), Graph Visualization tab:

with gr.TabItem("ğŸ“Š Graph Visualization"):
    gr.Markdown("### Interactive Knowledge Graph")

    # NEW: Interpretation guide
    with gr.Accordion("â„¹ï¸ How to Interpret the Graph", open=False):
        gr.Markdown("""
            **Node Colors** (by type):
            - ğŸ”µ Blue = Attributes (product features mentioned)
            - ğŸŸ¢ Green = Functional Consequences (what the product does/enables)
            - ğŸŸ£ Purple = Psychosocial Consequences (how it makes you feel)
            - ğŸ”´ Red = Terminal Values (end goals, life values)
            - ğŸŸ  Orange = Instrumental/Terminal Values

            **Node Size:**
            - Larger nodes = higher richness weight OR more visits during interview
            - Base size = richness weight Ã— 10
            - Visit bonus = visit count Ã— 5

            **Edges (Connections):**
            - Lines between nodes show causal relationships
            - Direction matters: A â†’ B means "A leads to B"
            - Edge types: leads_to, enables, fulfills, etc.

            **Disconnected Nodes:**
            - If you see many nodes without connections, it may indicate:
              1. The conversation didn't explore deeper "why" questions
              2. Responses mentioned features but not their benefits/consequences
              3. Edge extraction needs improvement (technical issue)

            **How to Get Better Graphs:**
            - Explain *why* features matter to you, not just what they are
            - Describe consequences and benefits
            - Answer "what does that enable?" and "why is that important?"
        """)

    graph_plot = gr.Plot(label="Graph Structure")
    # ... rest of tab ...
Implementation Checklist
Phase 1: Bug Fixes (CRITICAL - Do First)
 Change File components to visible=True (lines 364-389)
 Make export handlers async
 Add error handling and logging to export handlers
 Convert get_node_table() to return list[list]
 Convert get_edge_table() to return list[list]
 Test export buttons trigger downloads
 Test data tables display actual values
Phase 2: Graph Investigation (MEDIUM)
 Export JSON from user's interview session
 Analyze edge count vs node count
 Check validation logs for filtered edges
 Review question generation logic
 Add graph interpretation guide to UI
 Test with sample interview
 Document findings and recommendations
Phase 3: Extended Report (NEW FEATURE)
 Verify TurnLog model in data_models.py
 Add turn_logs storage to InterviewManager
 Modify process_response() to create TurnLog entries
 Create src/reporting/report_generator.py
 Implement generate_markdown_report()
 Add richness weight lookup for score breakdown
 Add export_extended_report() to InterviewSession
 Add export_extended_report_file() to InterviewUI
 Add extended report button to Export tab
 Wire up event handler
 Test extended report generation
 Verify Markdown formatting
Phase 4: Quality & Testing
 Format all code with black
 Run ruff checks
 Test all three export buttons
 Test data tables with real interview
 Test extended report with real interview
 Verify extended report shows richness breakdown correctly
 Create git commit with all changes
Critical Files to Modify
Phase 1 (Bug Fixes):
src/ui/gradio_app.py
Lines 234-253: get_node_table() format fix
Lines 255-277: get_edge_table() format fix
Lines 245-305: Make export handlers async, add logging
Lines 364-389: Change visible=False â†’ visible=True
Phase 2 (Investigation):
src/ui/gradio_app.py
Graph Visualization tab: Add interpretation guide accordion
Investigation files (read-only analysis):
src/interview/question_generator.py
src/interview/validator.py
prompts/extraction_prompts.yaml
Phase 3 (Extended Report):
src/core/data_models.py
Verify/update TurnLog model
src/interview/interview_manager.py
Add: turn_logs: list[TurnLog] = []
Modify: process_response() to create TurnLog entries
Add: get_turn_logs() method
src/reporting/report_generator.py (NEW FILE)
Create ReportGenerator class
Implement generate_markdown_report()
Implement _format_turn() helper
src/ui/gradio_app.py
Add: InterviewSession.export_extended_report()
Add: InterviewUI.export_extended_report_file()
Add: Extended report button + File component
Add: Event handler wiring
Testing Plan
Manual Testing - Phase 1 (Bug Fixes)
Start interview, complete 2-3 turns
Go to Export tab
Click "Download GraphML" â†’ should download file
Click "Download JSON" â†’ should download file
Click "Download Transcript" â†’ should download file
Go to Graph Visualization tab
Click "Refresh Visualization"
Verify node table shows actual data (not "[object Object]")
Verify edge table shows actual data (not "[object Object]")
Manual Testing - Phase 2 (Graph Interpretation)
Read graph interpretation guide in UI
Hover over nodes to see details
Check if edges are displayed between related concepts
Compare with user's interview transcript
Document any missing relationships
Manual Testing - Phase 3 (Extended Report)
Complete full interview (10+ turns)
Go to Export tab
Click "Download Extended Report (Markdown)"
Open downloaded .md file
Verify:
Turn-by-turn breakdown is complete
Richness score breakdown shows node contributions
LLM metadata is present
Validation errors/warnings are displayed
Markdown formatting is correct
Quotes are included
Sample Extended Report Output
# Extended Interview Report

**Session ID:** `20250129_143022_a4f8`
**Concept:** A premium coffee subscription service that delivers freshly roasted beans from local roasters every month.
**Date:** 2025-01-29 14:35:18
**Total Turns:** 8

---

## Summary Statistics

- **Total Nodes Extracted:** 15
- **Total Edges Extracted:** 8
- **Final Richness Score:** 12.50
- **Schema Coverage:** 45%

---

## Turn-by-Turn Analysis

### Turn 1

**Timestamp:** 2025-01-29T14:30:22

**Participant Response:**
> I like that it is local. I assume it means that the coffee is roasted locally and will be fresh.

**Interviewer Question:**
> That's great that freshness matters to you. How do you feel about getting coffee delivered to you monthly?

#### Extraction Results

**Nodes Added:**

- **local** (attribute)
  - Quote: "it is local"
- **freshness** (attribute)
  - Quote: "will be fresh"

*No edges extracted this turn*

#### Richness Score Breakdown

**Score Increase This Turn:** +1.00

**Contribution by Node:**

- local (attribute): +0.50 (weight)
- freshness (attribute): +0.50 (weight)

**Cumulative Richness:** 1.00

#### LLM Metadata

- Model: `kimi-k2`
- Tokens: 145
- Latency: 1234ms

---

### Turn 2

...
Next Steps After Implementation
Commit Phase 1 - "Fix export buttons and data table display (Gradio 6.x compatibility)"
Commit Phase 2 - "Add graph interpretation guide and investigate extraction issues"
Commit Phase 3 - "Add extended Markdown report with turn-by-turn breakdown and richness scoring"
Test locally - Verify all features work end-to-end
Deploy to HF Space - Test in production
User feedback - Collect feedback on reports and graph interpretation
Ready to implement! âœ… Priority order: Phase 1 (15 min) â†’ Phase 2 (1-2 hours) â†’ Phase 3 (2-3 hours) Purpose: Convert NetworkX graph to interactive Plotly figure
import plotly.graph_objects as go
import networkx as nx
from src.core.interview_graph import InterviewGraph

def create_plotly_graph(graph: InterviewGraph) -> go.Figure:
    """
    Create interactive Plotly visualization of interview graph.

    Features:
    - Nodes colored by type (attribute, value, consequence, etc.)
    - Node size by richness weight or visit count
    - Edges with arrows
    - Hover info: label, type, quotes, visit count
    - Layout: spring_layout or kamada_kawai
    """
    if graph.node_count == 0:
        # Return empty placeholder
        return go.Figure().add_annotation(
            text="No graph data yet",
            showarrow=False,
            font=dict(size=20)
        )

    # Get NetworkX graph
    G = graph.graph

    # Calculate layout
    pos = nx.spring_layout(G, k=1.5, iterations=50)

    # Define color map for node types
    color_map = {
        "attribute": "#3498db",       # Blue
        "functional_consequence": "#2ecc71",  # Green
        "psychosocial_consequence": "#9b59b6",  # Purple
        "value": "#e74c3c",           # Red
        "instrumental_value": "#f39c12",  # Orange
        "terminal_value": "#e67e22"   # Dark Orange
    }

    # Create edge traces
    edge_traces = []
    for edge in G.edges(data=True):
        x0, y0 = pos[edge[0]]
        x1, y1 = pos[edge[1]]

        edge_trace = go.Scatter(
            x=[x0, x1, None],
            y=[y0, y1, None],
            mode='lines',
            line=dict(width=1, color='#888'),
            hoverinfo='none',
            showlegend=False
        )
        edge_traces.append(edge_trace)

    # Create node trace
    node_x = []
    node_y = []
    node_colors = []
    node_sizes = []
    node_text = []
    node_hover = []

    for node_id in G.nodes():
        x, y = pos[node_id]
        node_data = G.nodes[node_id]['data']

        node_x.append(x)
        node_y.append(y)

        # Color by type
        node_colors.append(color_map.get(node_data.type, "#95a5a6"))

        # Size by richness weight + visit count
        base_size = graph.schema.get_richness_weight(node_data.type) * 10
        visit_bonus = node_data.visit_count * 5
        node_sizes.append(base_size + visit_bonus + 10)

        # Label
        node_text.append(node_data.label)

        # Hover info
        quotes_preview = "<br>".join(node_data.source_quotes[:2])
        if len(node_data.source_quotes) > 2:
            quotes_preview += f"<br>... +{len(node_data.source_quotes) - 2} more"

        hover_info = (
            f"<b>{node_data.label}</b><br>"
            f"Type: {node_data.type}<br>"
            f"Visits: {node_data.visit_count}<br>"
            f"Turn: {node_data.creation_turn}<br>"
            f"<br><i>Quotes:</i><br>{quotes_preview}"
        )
        node_hover.append(hover_info)

    node_trace = go.Scatter(
        x=node_x,
        y=node_y,
        mode='markers+text',
        marker=dict(
            size=node_sizes,
            color=node_colors,
            line=dict(width=2, color='white')
        ),
        text=node_text,
        textposition="top center",
        textfont=dict(size=10),
        hovertext=node_hover,
        hoverinfo='text',
        showlegend=False
    )

    # Create figure
    fig = go.Figure(data=edge_traces + [node_trace])

    fig.update_layout(
        title="Interview Knowledge Graph",
        showlegend=False,
        hovermode='closest',
        margin=dict(b=20, l=5, r=5, t=40),
        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
        height=600,
        plot_bgcolor='#f8f9fa'
    )

    return fig
2. InterviewSession Export Methods (src/ui/gradio_app.py)
Add these methods to InterviewSession class:
def export_graphml(self) -> bytes:
    """Export graph as GraphML file (bytes for download)."""
    if not self.manager:
        return b""

    import tempfile
    import os

    with tempfile.NamedTemporaryFile(mode='w', suffix='.graphml', delete=False) as f:
        temp_path = f.name

    try:
        self.manager.export_graph(temp_path)

        with open(temp_path, 'rb') as f:
            data = f.read()

        return data
    finally:
        if os.path.exists(temp_path):
            os.unlink(temp_path)

def export_json(self) -> dict:
    """Export graph as JSON (nodes + edges + metadata)."""
    if not self.manager:
        return {"nodes": [], "edges": [], "metadata": {}}

    nodes = []
    for node_id in self.manager.graph.graph.nodes():
        node_data = self.manager.graph.graph.nodes[node_id]['data']
        nodes.append({
            "id": node_data.id,
            "type": node_data.type,
            "label": node_data.label,
            "source_quotes": node_data.source_quotes,
            "creation_turn": node_data.creation_turn,
            "visit_count": node_data.visit_count
        })

    edges = []
    for source, target, edge_data in self.manager.graph.graph.edges(data=True):
        edge = edge_data['data']
        edges.append({
            "id": edge.id,
            "type": edge.type,
            "source": edge.source,
            "target": edge.target,
            "source_quote": edge.source_quote,
            "creation_turn": edge.creation_turn
        })

    metadata = {
        "session_id": self.session_id,
        "concept_description": self.concept_description,
        "turns": self.manager.turn_number if self.manager else 0,
        "richness": self.manager.graph.calculate_richness() if self.manager else 0.0,
        "node_count": len(nodes),
        "edge_count": len(edges)
    }

    return {
        "nodes": nodes,
        "edges": edges,
        "metadata": metadata
    }

def export_transcript(self) -> str:
    """Export conversation transcript as formatted text."""
    if not self.manager:
        return "No conversation yet."

    transcript = self.manager.get_conversation_transcript()

    lines = [
        "# Interview Transcript",
        f"Session ID: {self.session_id}",
        f"Concept: {self.concept_description}",
        f"Date: {self.session_id[:8]}",  # Timestamp from session_id
        "",
        "=" * 60,
        ""
    ]

    for i, msg in enumerate(transcript):
        role = "Interviewer" if msg["role"] == "assistant" else "Participant"
        lines.append(f"[{role}]")
        lines.append(msg["content"])
        lines.append("")

    lines.append("=" * 60)
    lines.append(f"Total turns: {self.manager.turn_number}")
    lines.append(f"Nodes extracted: {self.manager.graph.node_count}")
    lines.append(f"Edges extracted: {self.manager.graph.edge_count}")
    lines.append(f"Final richness: {self.manager.graph.calculate_richness():.2f}")

    return "\n".join(lines)

def get_node_table(self) -> list[dict]:
    """Get node data as table rows."""
    if not self.manager:
        return []

    rows = []
    for node_id in self.manager.graph.graph.nodes():
        node_data = self.manager.graph.graph.nodes[node_id]['data']
        rows.append({
            "ID": node_data.id,
            "Type": node_data.type,
            "Label": node_data.label,
            "Quotes": "; ".join(node_data.source_quotes[:2]),  # First 2 quotes
            "Visit Count": node_data.visit_count,
            "Turn": node_data.creation_turn
        })

    return rows

def get_edge_table(self) -> list[dict]:
    """Get edge data as table rows."""
    if not self.manager:
        return []

    rows = []
    for source, target, edge_data in self.manager.graph.graph.edges(data=True):
        edge = edge_data['data']
        rows.append({
            "ID": edge.id,
            "Type": edge.type,
            "Source": edge.source,
            "Target": edge.target,
            "Quote": edge.source_quote[:50] + "..." if len(edge.source_quote) > 50 else edge.source_quote,
            "Turn": edge.creation_turn
        })

    return rows

def visualize_graph(self):
    """Create Plotly visualization of graph."""
    from src.ui.graph_visualizer import create_plotly_graph

    if not self.manager:
        import plotly.graph_objects as go
        return go.Figure().add_annotation(
            text="No interview started yet",
            showarrow=False,
            font=dict(size=20)
        )

    return create_plotly_graph(self.manager.graph)
3. Updated Gradio UI (src/ui/gradio_app.py - build_interface())
Modify the InterviewUI.build_interface() method:
def build_interface(self) -> gr.Blocks:
    """Build the Gradio interface."""
    with gr.Blocks(title="AI Interview Assistant") as app:
        gr.Markdown("""
            # ğŸ™ï¸ AI Interview Assistant
            **Graph-driven adaptive interviewing for concept testing**
        """)

        # Concept input (same as before)
        with gr.Row():
            with gr.Column():
                gr.Markdown("### Step 1: Describe the Concept")
                concept_input = gr.Textbox(...)
                start_btn = gr.Button("Start Interview", variant="primary", size="lg")

        # Main interface with tabs
        with gr.Tabs():
            # Tab 1: Interview Chat (existing)
            with gr.TabItem("ğŸ’¬ Interview"):
                with gr.Row():
                    with gr.Column(scale=2):
                        chatbot = gr.Chatbot(label="Interview Conversation", height=500)
                        user_input = gr.Textbox(...)
                        with gr.Row():
                            submit_btn = gr.Button("Submit", variant="primary")
                            clear_btn = gr.Button("Clear & Restart")

                    with gr.Column(scale=1):
                        gr.Markdown("### Interview Progress")
                        session_id_display = gr.Textbox(...)
                        gr.Markdown("### Knowledge Graph Stats")
                        graph_stats = gr.JSON(...)

            # Tab 2: Graph Visualization (NEW)
            with gr.TabItem("ğŸ“Š Graph Visualization"):
                gr.Markdown("### Interactive Knowledge Graph")
                graph_plot = gr.Plot(label="Graph Structure")

                with gr.Row():
                    refresh_viz_btn = gr.Button("ğŸ”„ Refresh Visualization", size="sm")

                gr.Markdown("### Graph Data Tables")

                with gr.Row():
                    with gr.Column():
                        gr.Markdown("**Nodes**")
                        nodes_table = gr.Dataframe(
                            headers=["ID", "Type", "Label", "Quotes", "Visit Count", "Turn"],
                            interactive=False
                        )

                    with gr.Column():
                        gr.Markdown("**Edges**")
                        edges_table = gr.Dataframe(
                            headers=["ID", "Type", "Source", "Target", "Quote", "Turn"],
                            interactive=False
                        )

            # Tab 3: Export (NEW)
            with gr.TabItem("ğŸ’¾ Export"):
                gr.Markdown("""
                    ### Export Interview Results
                    Download graph data and conversation transcript in various formats.
                """)

                with gr.Row():
                    with gr.Column():
                        gr.Markdown("**Graph Formats**")
                        export_graphml_btn = gr.Button(
                            "ğŸ“¥ Download GraphML",
                            variant="secondary",
                            size="lg"
                        )
                        graphml_file = gr.File(
                            label="GraphML File (for Gephi, yEd, Cytoscape)",
                            visible=False
                        )

                        export_json_btn = gr.Button(
                            "ğŸ“¥ Download JSON",
                            variant="secondary",
                            size="lg"
                        )
                        json_file = gr.File(
                            label="JSON File (raw graph data)",
                            visible=False
                        )

                    with gr.Column():
                        gr.Markdown("**Conversation**")
                        export_transcript_btn = gr.Button(
                            "ğŸ“¥ Download Transcript",
                            variant="secondary",
                            size="lg"
                        )
                        transcript_file = gr.File(
                            label="Transcript File (text)",
                            visible=False
                        )

        # Event handlers (existing + new)

        # Start interview (existing)
        start_output = start_btn.click(
            fn=self.start_interview_with_concept,
            inputs=[concept_input],
            outputs=[chatbot, graph_stats, session_id_display]
        )

        # Submit response (existing)
        submit_btn.click(
            fn=self.process_response,
            inputs=[user_input, chatbot],
            outputs=[chatbot, user_input, graph_stats, session_id_display]
        )

        # Refresh visualization (NEW)
        refresh_viz_btn.click(
            fn=self.refresh_visualization,
            outputs=[graph_plot, nodes_table, edges_table]
        )

        # Export handlers (NEW)
        export_graphml_btn.click(
            fn=self.export_graphml_file,
            outputs=[graphml_file]
        )

        export_json_btn.click(
            fn=self.export_json_file,
            outputs=[json_file]
        )

        export_transcript_btn.click(
            fn=self.export_transcript_file,
            outputs=[transcript_file]
        )

        # Clear (existing)
        clear_btn.click(...)

    return app
4. InterviewUI Export Handlers (src/ui/gradio_app.py)
Add these methods to InterviewUI class:
def refresh_visualization(self):
    """Refresh graph visualization and tables."""
    if not self.current_session or not self.current_session.manager:
        import plotly.graph_objects as go
        empty_fig = go.Figure().add_annotation(
            text="Start an interview to see the graph",
            showarrow=False,
            font=dict(size=16)
        )
        return empty_fig, [], []

    # Get visualization
    fig = self.current_session.visualize_graph()

    # Get tables
    nodes_table = self.current_session.get_node_table()
    edges_table = self.current_session.get_edge_table()

    return fig, nodes_table, edges_table

def export_graphml_file(self):
    """Export GraphML file for download."""
    if not self.current_session or not self.current_session.manager:
        return None

    import tempfile

    graphml_bytes = self.current_session.export_graphml()

    # Write to temp file for Gradio File component
    temp_file = tempfile.NamedTemporaryFile(
        mode='wb',
        suffix='.graphml',
        delete=False,
        prefix=f"interview_{self.current_session.session_id}_"
    )
    temp_file.write(graphml_bytes)
    temp_file.close()

    return temp_file.name

def export_json_file(self):
    """Export JSON file for download."""
    if not self.current_session or not self.current_session.manager:
        return None

    import json
    import tempfile

    json_data = self.current_session.export_json()

    temp_file = tempfile.NamedTemporaryFile(
        mode='w',
        suffix='.json',
        delete=False,
        prefix=f"interview_{self.current_session.session_id}_"
    )
    json.dump(json_data, temp_file, indent=2)
    temp_file.close()

    return temp_file.name

def export_transcript_file(self):
    """Export transcript file for download."""
    if not self.current_session or not self.current_session.manager:
        return None

    import tempfile

    transcript_text = self.current_session.export_transcript()

    temp_file = tempfile.NamedTemporaryFile(
        mode='w',
        suffix='.txt',
        delete=False,
        prefix=f"transcript_{self.current_session.session_id}_"
    )
    temp_file.write(transcript_text)
    temp_file.close()

    return temp_file.name
Implementation Checklist
Core Components
 src/ui/graph_visualizer.py - NetworkX â†’ Plotly conversion
 InterviewSession.export_graphml() - GraphML bytes
 InterviewSession.export_json() - JSON dict
 InterviewSession.export_transcript() - Text string
 InterviewSession.get_node_table() - Table data
 InterviewSession.get_edge_table() - Table data
 InterviewSession.visualize_graph() - Plotly figure
UI Updates
 Add Tabs component (Interview, Visualization, Export)
 Add Graph Visualization tab with gr.Plot
 Add node/edge tables with gr.Dataframe
 Add Export tab with 3 download buttons
 Wire up event handlers
 Test all export formats
Dependencies
 Add plotly>=5.0.0 to requirements.txt
 Verify networkx already present
 Test Gradio 6.x compatibility with Plot/File components
Testing
 Test graph visualization with empty graph
 Test graph visualization with populated graph
 Test GraphML export and import in Gephi/yEd
 Test JSON export structure
 Test transcript formatting
 Test UI responsiveness with tabs
Quality
 Code formatted with black
 Ruff checks passing
 Docstrings complete
 Error handling for empty graphs
 Proper temp file cleanup
Critical Files to Modify
src/ui/gradio_app.py (MODIFY)
InterviewSession: Add 6 new methods
InterviewUI: Add 3 export handlers, 1 refresh handler
build_interface(): Add tabs, visualization, export UI
src/ui/graph_visualizer.py (NEW)
create_plotly_graph() function
Color mapping, layout, hover info
requirements.txt (MODIFY)
Add plotly>=5.0.0
Testing Plan
Manual Testing
Start interview, complete 3-5 turns
Switch to "Graph Visualization" tab
Verify interactive graph appears
Verify nodes colored by type
Verify hover shows quotes
Verify tables show all nodes/edges
Switch to "Export" tab
Download GraphML â†’ import in Gephi (verify structure)
Download JSON â†’ verify schema
Download Transcript â†’ verify formatting
Test with empty graph (before starting interview)
Should show placeholder messages
Automated Testing (Optional)
Unit test: test_graph_visualizer.py
Test create_plotly_graph() with fixtures
Verify figure structure
Integration test: Update test_ui_integration.py
Test export methods return expected formats
UI Layout Preview
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ™ï¸ AI Interview Assistant                                  â”‚
â”‚  Concept Input: [_______________________________] [Start]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  [ğŸ’¬ Interview] [ğŸ“Š Graph Visualization] [ğŸ’¾ Export]        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  GRAPH VISUALIZATION TAB:                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  Interactive Plotly Graph                         â”‚      â”‚
â”‚  â”‚  (nodes colored, sized, with hover info)          â”‚      â”‚
â”‚  â”‚  [Refresh Visualization]                          â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ Nodes Table         â”‚  â”‚ Edges Table             â”‚      â”‚
â”‚  â”‚ ID | Type | Label   â”‚  â”‚ Source | Target | Type  â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                             â”‚
â”‚  EXPORT TAB:                                                â”‚
â”‚  Graph Formats          Conversation                        â”‚
â”‚  [Download GraphML]     [Download Transcript]              â”‚
â”‚  [Download JSON]                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Next Steps After Implementation
Commit - "Add graph export and visualization features"
Test locally - Verify all exports and visualization work
Deploy to HF Space - Test in production environment
User feedback - Collect feedback on visualization usability