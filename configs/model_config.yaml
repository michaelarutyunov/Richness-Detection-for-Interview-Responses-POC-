# Model Configuration for AI Interview System
# Supports dual-model architecture: fast extraction + quality question generation

models:
  # Graph Processing (Fast, Structured Extraction)
  graph_processing:
    provider: "moonshot"  # Kimi API (OpenAI-compatible)
    model: "kimi-k2-turbo-preview"
    api_key_env: "KIMI_API_KEY"
    temperature: 0.3  # Low temperature for consistent extraction
    max_tokens: 1000
    timeout_seconds: 10
    # For structured output/function calling
    supports_function_calling: true
    supports_reasoning: false  # Turbo model doesn't have reasoning

  # Question Generation (Natural, Conversational)
  question_generation:
    provider: "moonshot"  # Kimi K2 Thinking (was: anthropic)
    model: "kimi-k2-thinking"  # (was: claude-sonnet-4-5)
    api_key_env: "KIMI_API_KEY"
    temperature: 1.0  # K2-thinking recommended temp (was: 0.7)
    max_tokens: 300  # Increased for reasoning content (was: 150)
    timeout_seconds: 15  # Increased for thinking latency (was: 5)
    supports_function_calling: true
    supports_reasoning: true  # NEW: Enable reasoning extraction

# Fallback Models (if primary fails)
fallbacks:
  graph_processing:
    - provider: "anthropic"
      model: "claude-haiku-4-5-20251001"
      api_key_env: "ANTHROPIC_API_KEY"
      temperature: 0.3
      max_tokens: 1000
      timeout_seconds: 10
      supports_function_calling: true
      supports_reasoning: false
    - provider: "openai"
      model: "gpt-4o-mini"
      api_key_env: "OPENAI_API_KEY"
      temperature: 0.3
      max_tokens: 1000
      timeout_seconds: 10
      supports_function_calling: true
      supports_reasoning: false

  question_generation:
    - provider: "anthropic"
      model: "claude-sonnet-4-5"
      api_key_env: "ANTHROPIC_API_KEY"
      temperature: 0.7
      max_tokens: 300
      timeout_seconds: 15
      supports_function_calling: true
      supports_reasoning: false
    - provider: "anthropic"
      model: "claude-haiku-4-5-20251001"
      api_key_env: "ANTHROPIC_API_KEY"
      temperature: 0.7
      max_tokens: 300
      timeout_seconds: 10
      supports_function_calling: true
      supports_reasoning: false

# Retry Configuration
retry_config:
  max_retries: 2
  initial_delay_seconds: 1
  backoff_multiplier: 2

# Rate Limiting
rate_limits:
  requests_per_minute: 60
  tokens_per_minute: 100000

# Provider-Specific Settings
provider_settings:
  moonshot:
    base_url: "https://api.moonshot.ai/v1"  # Kimi API endpoint
    request_timeout: 30

  anthropic:
    max_tokens_to_sample: 4096

  openai:
    organization: null  # Optional
