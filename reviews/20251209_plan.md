# Interview System Fix: Strategy Arbitration Layer

## Executive Assessment

Based on analysis of session_20251209_222404 and the comprehensive feedback document (/home/mikhailarutyunov/projects/Richness-Detection-for-Interview-Responses-POC-/reviews/20251209.md), the interview system exhibits **structurally sound architecture with immature control logic**. The system correctly implements graph extraction, coverage tracking, and momentum assessment, but the strategy selection mechanism creates systematic behavioral failures.

### Verified Critical Issues

1. **Strategy Monopolization** - 73% resolve_schema_tension vs 27% ensure_coverage
   - Asked "how does wateriness lead to weak foam" in 4 different variations (turns 5, 10, 11, 15)
   - User explicitly stated "i think i already spoke about it" at turn 16

2. **Knowledge Ceiling Ignored** - User said "I do not know much about enzymes" at turn 3
   - System asked 4+ more enzyme questions (turns 3, 4, 7, 8, 12, 13)
   - Misinterpreted lack of knowledge as lack of exploration

3. **Momentum Collapse Unhandled** - Momentum dropped to "low" at turn 7
   - Remained low for 9 consecutive turns (7-16)
   - System continued same strategy despite clear disengagement

4. **No Vertical Depth** - 41 nodes, 30 edges, all sensory/mechanical chains
   - No "why it matters" laddering to values
   - Graph captures WHAT (process flow) not WHY (meaning)

5. **Late Fatigue Detection** - Clear signals at turn 7-8 (hedging, repetition, closed responses)
   - System detected fatigue only at turn 16
   - No mid-course recovery tactics

### Root Cause

The `StrategySelector.select()` method in [src/decision/strategy.py:455-523](src/decision/strategy.py#L455-L523) implements **first-applicable-wins** logic:

```python
for strategy in self.strategies:
    if strategy.applies(...):
        return strategy, focus
```

This treats strategy selection as a **static priority queue** rather than a **dynamic utility optimization**. Momentum, fatigue, and redundancy are tracked but not used to influence selection.

## Recommended Solution

### Architecture: Add Utility-Based Arbitration Layer

Replace first-match selection with **multi-scorer arbitration** that preserves existing strategy definitions while adding intelligence:

```
Current Flow:
  for s in strategies:
    if s.applies(): return s  # First match wins

New Flow:
  candidates = [s for s in strategies if s.applies()]
  scored = [(score(s, context), s) for s in candidates]
  winner = max(scored, key=lambda x: x[0])
  return winner[1]
```

### 7 Targeted Scorers (Each Fixes One Problem)

| Scorer | Problem Fixed | Logic |
|--------|---------------|-------|
| **RecencyDiversityScorer** | Strategy monopolization | Penalize recently-used strategies (0.7x if used last turn) |
| **KnowledgeCeilingScorer** | Enzyme drilling | Detect "I don't know" patterns → 0.1x penalty for that element |
| **RedundancyScorer** | Repetitive questions | Semantic similarity check (Jaccard > 0.85) → 0.2x penalty |
| **MomentumAlignmentScorer** | Momentum collapse | Low momentum → boost breadth (1.5x), penalize depth (0.5x) |
| **VerticalLadderingScorer** | No values | Detect horizontal saturation → boost upward_linking (1.5x) |
| **CoverageQualityScorer** | Gap misinterpretation | Distinguish knowledge lack from exploration lack |
| **BranchHealthScorer** | Branch exhaustion | Detect stale branches → trigger explore_breadth |

## Implementation Plan

### Phase 1: Foundation (Core Infrastructure)

**File:** `src/decision/arbitration.py` (NEW)

Create base classes for scoring system:

```python
class ScoringContext:
    """All state needed for scoring decisions"""
    graph: Graph
    graph_state: GraphState
    coverage_state: CoverageState
    momentum: Momentum
    history: History
    recent_questions: List[str]  # Last 6 questions

class StrategyScorer(ABC):
    """Base class for all scorers"""
    @abstractmethod
    def score(self, strategy: Strategy, focus: FocusTarget, context: ScoringContext) -> float:
        """Return 0.0-2.0 multiplier (1.0 = neutral)"""
        pass

class ArbitrationEngine:
    """Orchestrates all scorers to select best strategy"""
    def __init__(self, scorers: List[StrategyScorer], weights: Dict[str, float]):
        self.scorers = scorers
        self.weights = weights

    def select_best(self, candidates: List[Tuple[Strategy, FocusTarget]], context: ScoringContext):
        """Score all candidates, return highest utility"""
        scored = []
        for strategy, focus in candidates:
            total_score = 1.0
            for scorer in self.scorers:
                multiplier = scorer.score(strategy, focus, context)
                total_score *= multiplier
            scored.append((total_score, strategy, focus))
        return max(scored, key=lambda x: x[0])
```

**File:** `src/decision/strategy.py` (MODIFY)

Add arbitration integration with feature flag:

```python
class StrategySelector:
    def __init__(self, ..., use_arbitration: bool = False, arbitration_engine: Optional[ArbitrationEngine] = None):
        self.use_arbitration = use_arbitration
        self.arbitration_engine = arbitration_engine

    def select(self, graph, graph_state, coverage_state, momentum, ...):
        if not self.use_arbitration:
            # Legacy path - existing logic
            return self._select_legacy(...)
        else:
            # New path - arbitration
            return self._select_arbitrated(...)

    def _select_arbitrated(self, ...):
        # Collect all applicable (strategy, focus) pairs
        candidates = []
        for strategy in self.strategies:
            if strategy.applies(...):
                focus = strategy.get_focus(...)
                if focus is not empty:
                    candidates.append((strategy, focus))

        # Build scoring context
        context = ScoringContext(
            graph=graph,
            graph_state=graph_state,
            coverage_state=coverage_state,
            momentum=momentum,
            history=history,
            recent_questions=self._get_recent_questions(history)
        )

        # Let arbitration engine choose
        score, strategy, focus = self.arbitration_engine.select_best(candidates, context)
        logger.info(f"[Arbitration] Selected {strategy.id} (utility score: {score:.3f})")
        return strategy, focus
```

### Phase 2: Core Scorers (High Impact)

**1. RedundancyScorer** (Fixes: Repetitive Questions)

```python
class RedundancyScorer(StrategyScorer):
    def score(self, strategy, focus, context):
        # Generate hypothetical question (quick template-based)
        hypothetical = self._generate_template_question(strategy, focus)

        # Check similarity to recent questions
        for past_q in context.recent_questions[-6:]:
            similarity = self._jaccard_similarity(hypothetical, past_q)
            if similarity > 0.85:
                logger.info(f"[Redundancy] Penalizing {strategy.id}: {similarity:.2f} similar to recent")
                return 0.2  # Heavy penalty
        return 1.0

    def _jaccard_similarity(self, q1, q2):
        words1 = set(self._normalize(q1).split())
        words2 = set(self._normalize(q2).split())
        intersection = words1 & words2
        union = words1 | words2
        return len(intersection) / len(union) if union else 0.0
```

**2. KnowledgeCeilingScorer** (Fixes: Enzyme Drilling)

```python
class KnowledgeCeilingScorer(StrategyScorer):
    def score(self, strategy, focus, context):
        # If focusing on element that respondent lacks knowledge about
        if focus.element:
            element_id = focus.element.id

            # Check recent responses for knowledge ceiling signals
            ceiling_detected = self._detect_knowledge_ceiling(element_id, context.history)

            if ceiling_detected:
                logger.info(f"[KnowledgeCeiling] Penalizing {strategy.id} for element '{element_id}'")
                return 0.1  # Severe penalty
        return 1.0

    def _detect_knowledge_ceiling(self, element_id, history):
        # Check last 3 responses for phrases indicating lack of knowledge
        patterns = [
            "i don't know",
            "not sure",
            "i do not know",
            "don't understand",
            "i heard about",
            "i guess",
            "i suppose"
        ]

        recent_responses = [t.response.lower() for t in history.turns[-3:]]

        for response in recent_responses:
            if any(pattern in response for pattern in patterns):
                return True
        return False
```

**3. MomentumAlignmentScorer** (Fixes: Momentum Collapse)

```python
class MomentumAlignmentScorer(StrategyScorer):
    def score(self, strategy, focus, context):
        momentum = context.momentum.level

        # Low momentum: favor breadth over depth
        if momentum == "low":
            if strategy.id in ["explore_breadth", "introduce_seed"]:
                logger.info(f"[Momentum] Boosting {strategy.id} for low momentum")
                return 1.5
            elif strategy.id in ["deepen_branch", "resolve_schema_tension"]:
                logger.info(f"[Momentum] Penalizing {strategy.id} for low momentum")
                return 0.5

        # High momentum: favor depth
        elif momentum == "high":
            if strategy.id in ["deepen_branch", "upward_linking"]:
                return 1.3

        return 1.0
```

### Phase 3: Advanced Scorers

**4. VerticalLadderingScorer** (Fixes: No Values)

Detects when horizontal elaboration saturates and boosts upward linking tactics.

**5. BranchHealthScorer** (Fixes: Branch Exhaustion)

Detects terminal nodes, stale branches (no new edges in N turns), triggers breadth exploration.

**6. CoverageQualityScorer** (Fixes: Gap Misinterpretation)

Adjusts coverage urgency based on whether lack of coverage is due to lack of knowledge vs lack of exploration.

**7. RecencyDiversityScorer** (Fixes: Strategy Monopolization)

Simple recency penalty: if strategy used in last N turns, apply 0.7x multiplier.

### Phase 4: Integration

**File:** `src/controller.py` (MODIFY)

Pass history to strategy selector:

```python
# Line ~407
strategy, focus = self.strategy_selector.select(
    self.graph,
    graph_state,
    self.coverage_state,
    self._momentum_tracker,
    self.node_focus_tracker,
    self.edge_focus_tracker,
    self.history  # ADD THIS
)
```

**File:** `src/config/interview_logic.yaml` (ADD SECTION)

```yaml
arbitration:
  enabled: true  # Feature flag
  scorers:
    - redundancy:
        weight: 1.0
        threshold: 0.85
    - knowledge_ceiling:
        weight: 1.0
        lookback_turns: 3
    - momentum_alignment:
        weight: 1.0
    - vertical_laddering:
        weight: 0.8
    - branch_health:
        weight: 0.7
    - coverage_quality:
        weight: 0.9
    - recency_diversity:
        weight: 0.6
```

### Phase 5: Testing & Validation

**File:** `tests/test_arbitration.py` (NEW)

Unit tests for each scorer:
- Test RedundancyScorer detects similar questions
- Test KnowledgeCeilingScorer detects "I don't know" patterns
- Test MomentumAlignmentScorer adjusts based on engagement
- Integration test: replay session_20251209_222404 with arbitration ON

Expected improvements:
- Strategy distribution: No strategy > 40% (vs 73%)
- Question uniqueness: All < 85% similarity (vs 4 identical)
- Knowledge ceiling: Switch after 2 signals (vs continues indefinitely)
- Fatigue onset: Delayed from turn 7 to turn 12+

## Critical Files

### Files to Create
1. **`src/decision/arbitration.py`** - All scorer classes + orchestration engine (~400 lines)
2. **`tests/test_arbitration.py`** - Comprehensive test suite (~300 lines)

### Files to Modify
3. **`src/decision/strategy.py`** - Add arbitration integration with feature flag (~50 lines added)
4. **`src/controller.py`** - Pass history to selector (~2 lines changed)
5. **`src/config/interview_logic.yaml`** - Add arbitration config section (~20 lines added)

### Files to Read (No Changes)
- `src/core/state.py` - Momentum, GraphState, CoverageState structures
- `src/core/history.py` - Turn and History structures
- `src/generation/generator.py` - Question generation patterns

## Implementation Sequence

1. **Week 1: Foundation**
   - Create arbitration.py with base classes
   - Add feature flag to StrategySelector
   - Verify legacy path unchanged

2. **Week 2: Core Scorers**
   - Implement Redundancy, KnowledgeCeiling, MomentumAlignment
   - Unit tests for each
   - Enable in dev environment

3. **Week 3: Advanced Scorers**
   - Implement remaining 4 scorers
   - Integration testing with replay
   - Tune weights and thresholds

4. **Week 4: Validation**
   - Run 10+ test interviews
   - Compare metrics to baseline
   - Document behavioral improvements

5. **Week 5: Production**
   - Gradual rollout (10% → 50% → 100%)
   - Monitor session metrics
   - Iterate on weights

## Success Metrics

| Metric | Baseline | Target | Measurement |
|--------|----------|--------|-------------|
| Strategy monopolization | 73% | <40% | Strategy distribution entropy |
| Question repetition | 4 duplicates | 0 duplicates | Jaccard similarity < 0.85 |
| Knowledge ceiling handling | Infinite | 2 signals | Stop after 2 "don't know" |
| Vertical depth | 5% value nodes | 20% | Node type distribution |
| Fatigue onset delay | Turn 7 | Turn 12+ | First low momentum |

## Rationale

This approach:
- ✅ **Preserves existing architecture** - No strategy YAML changes
- ✅ **Minimal disruption** - Feature flag allows safe rollout
- ✅ **Incremental fixes** - Each scorer addresses one problem
- ✅ **Observable** - Rich logging of all scorer outputs
- ✅ **Configurable** - Weights/thresholds in YAML
- ✅ **Testable** - Unit + integration + replay tests

The feedback document is correct: the strategy library is methodologically sound. The issue is **selection logic**, not **strategy definitions**. By adding an arbitration layer, we transform the system from a rule-based state machine into an adaptive interviewer that responds to conversational dynamics.
